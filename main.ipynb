{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46a6c6c",
   "metadata": {},
   "source": [
    "## Modeling Facade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cf8746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from models.baseline_ctr import BaselineCTRRegressor\n",
    "from models.multimodal_ctr import MultimodalCTRRegressor\n",
    "\n",
    "DATA_PATH = Path(\"data/data.csv\")\n",
    "IMAGES_ROOT = \"images\"  # folder with your creatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/b_pyg98x1dj97pbflpck32d80000gn/T/ipykernel_6595/3827788563.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"time\"] = pd.to_datetime(df[\"time\"])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "campaign_item_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "no_of_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ext_service_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ext_service_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creative_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "search_tags",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "template_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "landing_page",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "advertiser_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "advertiser_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "network_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "approved_budget",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "advertiser_currency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "channel_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "channel_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_bid_cpm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "network_margin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "campaign_budget_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "impressions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "clicks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stats_currency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "currency_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exchange_rate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "media_cost_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "search_tag_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cmi_currency_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timezone",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weekday_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "keywords",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3912d3ec-ca59-4fa6-9022-779ed4a77f95",
       "rows": [
        [
         "0",
         "2733",
         "7",
         "2022-05-01 00:00:00",
         "128",
         "Facebook Ads",
         "1000",
         "#The Power of X",
         "90.0",
         "https://www.abcjewelry.com/collections/boho-jewelry-for-women",
         "4756",
         "Web",
         "190",
         "400.0",
         "SGD",
         "32",
         "Mobile",
         null,
         "0",
         "652.173913",
         "837",
         "8",
         "SGD",
         "SGD",
         "1",
         "14.058514",
         "Others",
         "SGD",
         "Asia/Singapore",
         "week_end",
         "delicate bracelets"
        ],
        [
         "1",
         "2766",
         "23",
         "2022-05-01 00:00:00",
         "16",
         "DV360",
         "13720",
         "#Embrace Your Individuality with X",
         null,
         "https://www.abcjewelry.com/women/affordable-jewelry/",
         "5209",
         "Brand",
         "287",
         "22000.0",
         "USD",
         "32",
         "Mobile",
         "1.0",
         "0",
         "325.0",
         "1234",
         "23",
         "USD",
         "USD",
         "1",
         "16.368097",
         "Others",
         "USD",
         "America/New_York",
         "week_end",
         "trendy and timeless jewelry"
        ],
        [
         "2",
         "3543",
         "9",
         "2022-05-01 00:00:00",
         "16",
         "DV360",
         "13530",
         "#The Power of X",
         "90.0",
         "https://www.abcjewelry.com/collections/hoop-earrings-for-women",
         "6370",
         "North",
         "353",
         "5000.0",
         "INR",
         "64",
         "Video",
         null,
         "0",
         "3814.546793",
         "1851",
         "47",
         "INR",
         "INR",
         "1",
         "24.06976",
         "Others",
         "INR",
         "Asia/Kolkata",
         "week_end",
         "party jewelry"
        ],
        [
         "3",
         "3389",
         "0",
         "2022-05-01 00:00:00",
         "16",
         "DV360",
         "15500",
         "#The Power of X",
         null,
         "https://www.abcjewelry.com/collections/unique-jewelry-for-women",
         "6292",
         "Andhra Pradesh",
         "353",
         "5000.0",
         "INR",
         "8",
         "Social",
         null,
         "0",
         "1225.640397",
         "581",
         "9",
         "INR",
         "INR",
         "1",
         "0.740751",
         "Others",
         "INR",
         "Asia/Kolkata",
         "week_end",
         "long necklaces"
        ],
        [
         "4",
         "3543",
         "16",
         "2022-05-01 00:00:00",
         "4",
         "Google Ads",
         "13525",
         "#Be Bold. Be X",
         "90.0",
         "https://www.abcjewelry.com/collections/gemstone-jewelry-for-women",
         "6370",
         "North",
         "353",
         "5000.0",
         "INR",
         "64",
         "Video",
         null,
         "0",
         "9812.339016",
         "13518",
         "1003",
         "INR",
         "INR",
         "1",
         "168.39305",
         "Others",
         "INR",
         "Asia/Kolkata",
         "week_end",
         "long necklaces"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_item_id</th>\n",
       "      <th>no_of_days</th>\n",
       "      <th>time</th>\n",
       "      <th>ext_service_id</th>\n",
       "      <th>ext_service_name</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>search_tags</th>\n",
       "      <th>template_id</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>...</th>\n",
       "      <th>clicks</th>\n",
       "      <th>stats_currency</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>exchange_rate</th>\n",
       "      <th>media_cost_usd</th>\n",
       "      <th>search_tag_cat</th>\n",
       "      <th>cmi_currency_code</th>\n",
       "      <th>timezone</th>\n",
       "      <th>weekday_cat</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2733</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>128</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>1000</td>\n",
       "      <td>#The Power of X</td>\n",
       "      <td>90.0</td>\n",
       "      <td>https://www.abcjewelry.com/collections/boho-je...</td>\n",
       "      <td>4756</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>SGD</td>\n",
       "      <td>SGD</td>\n",
       "      <td>1</td>\n",
       "      <td>14.058514</td>\n",
       "      <td>Others</td>\n",
       "      <td>SGD</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>week_end</td>\n",
       "      <td>delicate bracelets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2766</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>16</td>\n",
       "      <td>DV360</td>\n",
       "      <td>13720</td>\n",
       "      <td>#Embrace Your Individuality with X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.abcjewelry.com/women/affordable-je...</td>\n",
       "      <td>5209</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>16.368097</td>\n",
       "      <td>Others</td>\n",
       "      <td>USD</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>week_end</td>\n",
       "      <td>trendy and timeless jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3543</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>16</td>\n",
       "      <td>DV360</td>\n",
       "      <td>13530</td>\n",
       "      <td>#The Power of X</td>\n",
       "      <td>90.0</td>\n",
       "      <td>https://www.abcjewelry.com/collections/hoop-ea...</td>\n",
       "      <td>6370</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1</td>\n",
       "      <td>24.069760</td>\n",
       "      <td>Others</td>\n",
       "      <td>INR</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "      <td>week_end</td>\n",
       "      <td>party jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3389</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>16</td>\n",
       "      <td>DV360</td>\n",
       "      <td>15500</td>\n",
       "      <td>#The Power of X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.abcjewelry.com/collections/unique-...</td>\n",
       "      <td>6292</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740751</td>\n",
       "      <td>Others</td>\n",
       "      <td>INR</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "      <td>week_end</td>\n",
       "      <td>long necklaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3543</td>\n",
       "      <td>16</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>Google Ads</td>\n",
       "      <td>13525</td>\n",
       "      <td>#Be Bold. Be X</td>\n",
       "      <td>90.0</td>\n",
       "      <td>https://www.abcjewelry.com/collections/gemston...</td>\n",
       "      <td>6370</td>\n",
       "      <td>...</td>\n",
       "      <td>1003</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1</td>\n",
       "      <td>168.393050</td>\n",
       "      <td>Others</td>\n",
       "      <td>INR</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "      <td>week_end</td>\n",
       "      <td>long necklaces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_item_id  no_of_days       time  ext_service_id ext_service_name  \\\n",
       "0              2733           7 2022-05-01             128     Facebook Ads   \n",
       "1              2766          23 2022-05-01              16            DV360   \n",
       "2              3543           9 2022-05-01              16            DV360   \n",
       "3              3389           0 2022-05-01              16            DV360   \n",
       "4              3543          16 2022-05-01               4       Google Ads   \n",
       "\n",
       "   creative_id                         search_tags  template_id  \\\n",
       "0         1000                     #The Power of X         90.0   \n",
       "1        13720  #Embrace Your Individuality with X          NaN   \n",
       "2        13530                     #The Power of X         90.0   \n",
       "3        15500                     #The Power of X          NaN   \n",
       "4        13525                      #Be Bold. Be X         90.0   \n",
       "\n",
       "                                        landing_page  advertiser_id  ...  \\\n",
       "0  https://www.abcjewelry.com/collections/boho-je...           4756  ...   \n",
       "1  https://www.abcjewelry.com/women/affordable-je...           5209  ...   \n",
       "2  https://www.abcjewelry.com/collections/hoop-ea...           6370  ...   \n",
       "3  https://www.abcjewelry.com/collections/unique-...           6292  ...   \n",
       "4  https://www.abcjewelry.com/collections/gemston...           6370  ...   \n",
       "\n",
       "  clicks  stats_currency  currency_code exchange_rate  media_cost_usd  \\\n",
       "0      8             SGD            SGD             1       14.058514   \n",
       "1     23             USD            USD             1       16.368097   \n",
       "2     47             INR            INR             1       24.069760   \n",
       "3      9             INR            INR             1        0.740751   \n",
       "4   1003             INR            INR             1      168.393050   \n",
       "\n",
       "  search_tag_cat  cmi_currency_code          timezone  weekday_cat  \\\n",
       "0         Others                SGD    Asia/Singapore     week_end   \n",
       "1         Others                USD  America/New_York     week_end   \n",
       "2         Others                INR      Asia/Kolkata     week_end   \n",
       "3         Others                INR      Asia/Kolkata     week_end   \n",
       "4         Others                INR      Asia/Kolkata     week_end   \n",
       "\n",
       "                      keywords  \n",
       "0           delicate bracelets  \n",
       "1  trendy and timeless jewelry  \n",
       "2                party jewelry  \n",
       "3               long necklaces  \n",
       "4               long necklaces  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "644215ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58089, 30), (14523, 30))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "split_idx = int(len(df) * (1.0 - test_size))\n",
    "\n",
    "df_train = df.iloc[:split_idx].reset_index(drop=True)\n",
    "df_test = df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f72506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline tabular-only metrics:\n",
      "rmse: 0.004463\n",
      "mae: 0.001612\n",
      "r2: 0.816840\n"
     ]
    }
   ],
   "source": [
    "baseline = BaselineCTRRegressor()\n",
    "baseline.fit(df_train)\n",
    "baseline_metrics = baseline.evaluate(df_test)\n",
    "\n",
    "print(\"Baseline tabular-only metrics:\")\n",
    "for k, v in baseline_metrics.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfcdd89a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify input_ids",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m multimodal = MultimodalCTRRegressor(images_root=IMAGES_ROOT, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmultimodal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m multimodal_metrics = multimodal.evaluate(df_test)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMultimodal (tabular + image) metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/models/multimodal_ctr.py:126\u001b[39m, in \u001b[36mMultimodalCTRRegressor.fit\u001b[39m\u001b[34m(self, df_train)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, df_train: pd.DataFrame) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    117\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    Fits the multimodal regressor on the training dataframe.\u001b[39;00m\n\u001b[32m    119\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m \u001b[33;03m        features and a 'creative_id' column.\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     X_train, y_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_feature_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_scalers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/models/multimodal_ctr.py:104\u001b[39m, in \u001b[36mMultimodalCTRRegressor._build_feature_matrix\u001b[39m\u001b[34m(self, df, fit_scalers)\u001b[39m\n\u001b[32m    101\u001b[39m X_tab_num = X_df[numeric_cols].values.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m image_paths = \u001b[38;5;28mself\u001b[39m._build_image_paths(df_ctr)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m X_img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimage_embedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fit_scalers:\n\u001b[32m    107\u001b[39m     X_tab_scaled = \u001b[38;5;28mself\u001b[39m.tabular_scaler.fit_transform(X_tab_num)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/features/image_embedder.py:63\u001b[39m, in \u001b[36mImageEmbedder.encode_paths\u001b[39m\u001b[34m(self, image_paths, batch_size)\u001b[39m\n\u001b[32m     60\u001b[39m     images.append(img)\n\u001b[32m     62\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.processor(images=images, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(outputs, \u001b[33m\"\u001b[39m\u001b[33mpooler_output\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     66\u001b[39m     batch_emb = outputs.pooler_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:989\u001b[39m, in \u001b[36mCLIPModel.forward\u001b[39m\u001b[34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, interpolate_pos_encoding)\u001b[39m\n\u001b[32m    978\u001b[39m output_hidden_states = (\n\u001b[32m    979\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m vision_outputs: BaseModelOutputWithPooling = \u001b[38;5;28mself\u001b[39m.vision_model(\n\u001b[32m    983\u001b[39m     pixel_values=pixel_values,\n\u001b[32m    984\u001b[39m     output_attentions=output_attentions,\n\u001b[32m    985\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m    986\u001b[39m     interpolate_pos_encoding=interpolate_pos_encoding,\n\u001b[32m    987\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m text_outputs: BaseModelOutputWithPooling = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m image_embeds = vision_outputs.pooler_output\n\u001b[32m    998\u001b[39m image_embeds = \u001b[38;5;28mself\u001b[39m.visual_projection(image_embeds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:598\u001b[39m, in \u001b[36mCLIPTextTransformer.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states)\u001b[39m\n\u001b[32m    593\u001b[39m output_hidden_states = (\n\u001b[32m    594\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    595\u001b[39m )\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to specify input_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    600\u001b[39m input_shape = input_ids.size()\n\u001b[32m    601\u001b[39m input_ids = input_ids.view(-\u001b[32m1\u001b[39m, input_shape[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: You have to specify input_ids"
     ]
    }
   ],
   "source": [
    "multimodal = MultimodalCTRRegressor(images_root=IMAGES_ROOT, device=\"cpu\")\n",
    "multimodal.fit(df_train)\n",
    "multimodal_metrics = multimodal.evaluate(df_test)\n",
    "\n",
    "print(\"Multimodal (tabular + image) metrics:\")\n",
    "for k, v in multimodal_metrics.items():\n",
    "    print(f\"{k}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36dae86",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify input_ids",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m df_sample = df_test.sample(n=\u001b[32m5\u001b[39m, random_state=\u001b[32m42\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m baseline_pred = baseline.predict(df_sample)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m multimodal_pred = \u001b[43mmultimodal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m comparison = df_sample[[\u001b[33m\"\u001b[39m\u001b[33mcampaign_item_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcreative_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclicks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimpressions\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n\u001b[32m      7\u001b[39m comparison[\u001b[33m\"\u001b[39m\u001b[33mtrue_ctr\u001b[39m\u001b[33m\"\u001b[39m] = df_sample[\u001b[33m\"\u001b[39m\u001b[33mclicks\u001b[39m\u001b[33m\"\u001b[39m] / df_sample[\u001b[33m\"\u001b[39m\u001b[33mimpressions\u001b[39m\u001b[33m\"\u001b[39m].clip(lower=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/models/multimodal_ctr.py:143\u001b[39m, in \u001b[36mMultimodalCTRRegressor.predict\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd.DataFrame) -> np.ndarray:\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Predicts CTR for a dataframe.\u001b[39;00m\n\u001b[32m    132\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m \u001b[33;03m        Predicted CTR values.\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     X, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_feature_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_scalers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.model.predict(X)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m preds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/models/multimodal_ctr.py:104\u001b[39m, in \u001b[36mMultimodalCTRRegressor._build_feature_matrix\u001b[39m\u001b[34m(self, df, fit_scalers)\u001b[39m\n\u001b[32m    101\u001b[39m X_tab_num = X_df[numeric_cols].values.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m image_paths = \u001b[38;5;28mself\u001b[39m._build_image_paths(df_ctr)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m X_img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimage_embedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fit_scalers:\n\u001b[32m    107\u001b[39m     X_tab_scaled = \u001b[38;5;28mself\u001b[39m.tabular_scaler.fit_transform(X_tab_num)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smartassets_ml_challenge/features/image_embedder.py:63\u001b[39m, in \u001b[36mImageEmbedder.encode_paths\u001b[39m\u001b[34m(self, image_paths, batch_size)\u001b[39m\n\u001b[32m     60\u001b[39m     images.append(img)\n\u001b[32m     62\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.processor(images=images, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(outputs, \u001b[33m\"\u001b[39m\u001b[33mpooler_output\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     66\u001b[39m     batch_emb = outputs.pooler_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:989\u001b[39m, in \u001b[36mCLIPModel.forward\u001b[39m\u001b[34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, interpolate_pos_encoding)\u001b[39m\n\u001b[32m    978\u001b[39m output_hidden_states = (\n\u001b[32m    979\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m vision_outputs: BaseModelOutputWithPooling = \u001b[38;5;28mself\u001b[39m.vision_model(\n\u001b[32m    983\u001b[39m     pixel_values=pixel_values,\n\u001b[32m    984\u001b[39m     output_attentions=output_attentions,\n\u001b[32m    985\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m    986\u001b[39m     interpolate_pos_encoding=interpolate_pos_encoding,\n\u001b[32m    987\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m text_outputs: BaseModelOutputWithPooling = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m image_embeds = vision_outputs.pooler_output\n\u001b[32m    998\u001b[39m image_embeds = \u001b[38;5;28mself\u001b[39m.visual_projection(image_embeds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:598\u001b[39m, in \u001b[36mCLIPTextTransformer.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states)\u001b[39m\n\u001b[32m    593\u001b[39m output_hidden_states = (\n\u001b[32m    594\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    595\u001b[39m )\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to specify input_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    600\u001b[39m input_shape = input_ids.size()\n\u001b[32m    601\u001b[39m input_ids = input_ids.view(-\u001b[32m1\u001b[39m, input_shape[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: You have to specify input_ids"
     ]
    }
   ],
   "source": [
    "df_sample = df_test.sample(n=5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "baseline_pred = baseline.predict(df_sample)\n",
    "multimodal_pred = multimodal.predict(df_sample)\n",
    "\n",
    "comparison = df_sample[[\"campaign_item_id\", \"creative_id\", \"clicks\", \"impressions\"]].copy()\n",
    "comparison[\"true_ctr\"] = df_sample[\"clicks\"] / df_sample[\"impressions\"].clip(lower=1)\n",
    "comparison[\"baseline_ctr_pred\"] = baseline_pred\n",
    "comparison[\"multimodal_ctr_pred\"] = multimodal_pred\n",
    "\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
